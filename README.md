#Shared Neural Item Representations for Completely Cold Start Problem

This is our official implementation for the paper:

Ramin Raziperchikolaei, Guannan Liang, and Young-joo Chung. 2021. Shared Neural Item Representations for Completely Cold Start Problem. 
Proceedings of the 14th ACM Conference on Recommender Systems (RecSys 2021), September 2021.
https://doi.org/10.1145/3460231.3474228

To solve the item cold-start problem, most previous works follow a two-branch setting, 
where user and item networks learn user and item representations 
in the first and second branches, respectively. 
In this paper, we will show that by using this structure, two representations are learned for each item in the training set; one is the output of the item network and the other one is hidden inside the user network and is used for learning user representations. Learning two representations makes training slower and optimization more difficult. 
We propose to unify the two representations and only use the one generated by the item network. Also, we will show how attention mechanisms fit in our setting and how they can improve the quality of the representations. Our results on public and real-world datasets show that our approach converges faster, achieves higher recall in fewer iterations, and is more robust to the changes in the number of training samples compared to the previous works.

## Environment Settings
- python '3.6.9'
- numpy '1.18.5'
- torch '1.6.0'
- scipy '1.7.3'
 
## Example to run the codes.

```
python main.py --ds citeulike --model shared_model --num_epochs 50 --batch_size 32 --lr 0.001
python main.py --ds citeulike --model shared_model_attention --remove_item --num_epochs 50 --batch_size 32 --lr 0.001 
```


### Dataset
We provide the files to run our method on the CiteULike dataset.
We use the files provided by the implementation of the DropoutNet: https://github.com/layer6ai-labs/DropoutNet

We also provide instructions on how to create files for any other dataset.

We have put the following files in the citeulike folder:

**trainset.npy**
- This is an N*3 numpy matrix, where N is number of interactions in the training set.
- Each row is a training instance: `userID itemID interaction`
- Interactin values is 1 (positive) or -1 (negative).


**item_dict.pkl**
- This is a dictionary of items' features.
- The key of the dictionary is an item_id.
- The value for each key is a featue vector.
- In case of the CiteULike dataset, each feature vector is 300-dimensional.

**user_dict.pkl**
- This is a dictionary of users' features.
- We converted all the features to binary.
- The key of the dictionary is a user_id.
- The value fo each key is a list of the indices of the items purchased by the key user.

**test_items_ids.pkl**
- This is a list of the indices of the (cold-start) test items.

**val_grtr.pkl**
- This is a dictionary used only for the purpose of computing recall.
- The key of the dictionary is a (test) user id.
- The value for each key (test user) is a list of the form [i_items,n_items].
    - i_items is a list of the cold-start items that the key user interacted with.
    - n_items is a list of the cold-start items that the key user did not interacted with.

### How to run the code for a new dataset
- Create a folder with the name "new_dataset".
- Create the above five files and put them in this folder.
- Run the code with the: --ds "new_dataset"
- The dataset.py file in the citeulike folder shows how to create the above five files.

### Results
We report Recall after each epoch.
Each epoch takes around 10 minutes.
We got Recall=67.1% on CiteULike dataset.

